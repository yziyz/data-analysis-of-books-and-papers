# data-analysis-of-books-and-papers
> 通过书籍的“作者、标题、中图分类”与论文的“作者、关键词、领域”进行分步关联处理，最后将节点(图书或论文)保存成文本文件，导入图数据库中。

## 一、源文件
> 由图书(来源是图书馆)、论文(来源是万方和知网)的数据库表导出成的文本文件。

### 1.图书数据文件：
#### 图书ID与作者关联文件(book_id_author.txt)
```
8473#王珏, 周志华, 周傲英
539627#周志华，杨强
```
 
#### 图书ID与中图法分类号关联文件(book_id_CLCId.txt)
```
8473,TP181
539627,TP181
```
 
#### 中图法分类号与中图法分类名关联文件(cls_no_name.txt)
```
TP181,自动推理、机器学习
G252.7,文献检索
```
 
### 2.论文数据文件：
#### 论文ID与论文系统唯一标识关联文件(paper_id_paperId.txt)
```
48368,10284-1016003545.nh
269170,JSGG200101018
```
 
#### 论文系统唯一标识与论文作者关联文件(paper_paperId_author.txt)
```
10284-1016003545.nh,周志华
JSGG200101018,周志华
```
 
#### 论文系统唯一标识与论文领域名称关联文件(paper_paperId_field.txt)
```
10284-1016003545.nh,自动化技术
JSGG200101018,自动化技术
```
 
#### 论文系统唯一标识与论文关键词关联文件(paper_paperId_indexTerm.txt)
```
10284-1016003545.nh,机器学习
10284-1016003545.nh,凸松弛
```

## 二、思路
> 分为四个步骤，最终得到节点权重和关联信息的文本文件，导入图数据库中使用。

### 1.第一步骤
#### 目的：
获得7个图的顶点的二进制文件与边的文本文件。

#### 实现：
> 在类edu.libsys.stats.GetEdgeAndVertices中完成；在更新权重后，此步骤不需要重新执行。

1)根据“图书、论文源数据”，建立ID(图书、论文)与属性(作者、中图法分类号、中图法分类名、领域名称、关键词)的RDD(Spark中的概念，分布式弹性数据集)

2)不同RDD之间进行Join计算，获得根据某一属性相同的ID与ID的RDD；

3)建立7个图，获得7个图的顶点的二进制文件与边的文本文件。

### 2.第二步骤
#### 目的：
根据边文件导出图书、论文关联CSV文件，便于导入图数据库Neo4j中；在更新权重后，此步骤不需要重新执行。

#### 实现：
> 在类edu.libsys.stats.GetRelationship中完成

1)读取边的文本文件，使用方法对每行文本做处理；

2)7个RDD，保存成三个文件(Spark保存成文件会分块保存在同一目录下)，即图书与图书(bookBookRelationships)、论文与论文(paperPaperRelationships)、图书与论文(bookPaperRelationships)。

### 3.第三步骤
##### 目的：
根据“节点、边文件”计算出“每个节点的入度”，并保存为文本文件；在更新权重后，此步骤不需要重新执行。
#### 实现：
> 在类edu.libsys.stats.GetInDegrees中完成

1)读取顶点的二进制文件与边的文本文件，生成7个图；

2)根据7个图的入度RDD与节点RDD做fullOuterJoin计算，得到每个节点的入度，保存成7个文本文件。

### 4.第四步骤
#### 目的：
根据“入度文件”和“edu.libsys.conf.Conf类中配置的权重”，计算“每个节点的三种权重”，保存成文本文件；在更新权重后，此步骤需要重新执行。
#### 实现：
> 在类edu.libsys.Main中完成

1)读取7个入度文件，将每个节点的入度与相应权重（3套权证）相乘，得到21个RDD；

2)分权重类型整合成3个权重RDD；

3)将3个权重RDD根据ID整合到一个权重RDD；

4)分为图书、论文保存；
